{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Decision Tree\n",
    "\n",
    "## a.) Check out dt.py\n",
    "\n",
    "## b.) Check out dt.py\n",
    "\n",
    "## c.) See Below for 1C\n",
    "\n",
    "## d.) \n",
    "\n",
    "For every split, since the train method goes through every *d* feature, through all their *n* values to get the optimal split, for this mandatory method so far we have at least *dn*\n",
    "\n",
    "For each level, we have one split, so since we train at each level to the maximum depth, so let us make the depth of the entire tree *p*. Thus, we get O(*dnp*). This is for train.\n",
    "\n",
    "For predict, it is O(*np*) because this is like searching in a binary tree getting to the leaf node, which results in the max depth, where predict, from the root to the leaf it results in makes a comparison to reach that node (which costs *np*), *n* for each comparison.   \n",
    "Predict would have take make a comparison for every node from and including the root till that leaf.\n",
    "\n",
    "Overall, O(*dnp*) + O(*np*) = O(*dnp*) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - c.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7f3b15fe4c4c49826cf36a67e72498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minLeafSample = np.arange(10,31)\n",
    "maxDepth = np.arange(1,16)\n",
    "X, Y = np.meshgrid(maxDepth, minLeafSample)\n",
    "trainAcc_gini = np.zeros((31,10))\n",
    "testAcc_gini = np.zeros((31,10))\n",
    "trainAcc_entropy = np.zeros((31,10))\n",
    "testAcc_entropy = np.zeros((31,10))\n",
    "\n",
    "xTrain = pd.read_csv('q4xTrain.csv')\n",
    "yTrain = pd.read_csv('q4yTrain.csv')\n",
    "xTest = pd.read_csv('q4xTest.csv')\n",
    "yTest = pd.read_csv('q4yTest.csv')\n",
    "\n",
    "def accTest(criterion, maxDepth, minLeafSample):\n",
    "    return dt.dt_train_test(dt.DecisionTree(criterion, maxDepth, minLeafSample), xTrain, yTrain, xTest, yTest)\n",
    "\n",
    "for i in tqdm(range(31)):\n",
    "    for j in range(10):\n",
    "        trainAcc, testAcc = accTest('gini', maxDepth[j], minLeafSample[i])\n",
    "        trainAcc_gini[i][j] = trainAcc\n",
    "        testAcc_gini[i][j] = testAcc\n",
    "        trainAcc, testAcc = accTest('entropy', maxDepth[j], minLeafSample[i])\n",
    "        trainAcc_entropy[i][j] = trainAcc\n",
    "        testAcc_entropy[i][j] = testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rc('xtick', labelsize=15) \n",
    "plt.rc('ytick', labelsize=15) \n",
    "fig = plt.figure(figsize=(20,15))\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_wireframe(X, Y, testAcc_gini, cmap = 'plasma')\n",
    "#surf = ax.plot_wireframe(X, Y, testAcc_entropy, cmap='inferno')\n",
    "ax.set_xlabel('Max depth')\n",
    "ax.set_ylabel('Min leaf samples')\n",
    "ax.set_zlabel('Accuracy')\n",
    "ax.text2D(0.1, 0.9, \"Test Data Accuracy with Gini\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Analysis\n",
    "\n",
    "We can see here that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Check out q2.py\n",
    "\n",
    "## b.) Check out q2.py\n",
    "\n",
    "## c.) Check out q2.py\n",
    "\n",
    "## d.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are three runs of the model assessment, which is the amount of runs my laptop would fit on the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model Assessment](q3.PNG)\n",
    "```Python\n",
    "6   True Test  0.954458  0.828526  0.000000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "### AUC Comparison:\n",
    "\n",
    "We can see that TrainAUC is higher than ValAUC at every single row and column position, and this remains consistently so. We can assume that there is at least a general .1 advantage to TrainAUC vs. ValAUC for any strategy. For variance, which can be seen below in generality, the Value AUC's variate much more than Train AUC in general.\n",
    "\n",
    "### Different Model Selection Techniques vs. AUC:\n",
    "\n",
    "TrainAUC and ValAUC seems generally similar for each technique, but through a thorough analysis of variances, we can see that:\n",
    "\n",
    "After running my code 50 times:\n",
    "\n",
    "![MA](q2analysiscode.PNG)\n",
    "![MA](q2analysiscode2.PNG)\n",
    "![MA](q2analysiscode3.PNG)\n",
    "![MA](q3analysiscode4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "Overall the value AUC here has much more variation than the training, and the training values variances are very small, which is good. \n",
    "\n",
    "#### For Holdout:\n",
    "Holdout value variance is extremely high!\n",
    "\n",
    "#### For K-Fold:\n",
    "\n",
    "K-folds value variance are decent, especially K-2 and K-5, which are very close to each other. K-10 is generally worse, but is still not as bad as holdout value variance.\n",
    "\n",
    "#### For MCCV:\n",
    "\n",
    "MCCV value variances are extremely high as well, comparable to holdout. MCCV-10 does better than MCCV-5 surprisingly for the average of 50 runs.\n",
    "\n",
    "#### Overall:\n",
    "\n",
    "From this, since 5-fold has low value variance and has pretty good performance, generally better than k-2 for ValAUC, being closer to .8, 5-fold should be the best and most robust, a good compromise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Time:\n",
    "\n",
    "#### Holdout & True-test:\n",
    "\n",
    "True Test is always the fastest, with holdout sometimes coming in 2nd.\n",
    "\n",
    "My laptop is just so speedy that sometimes holdout gives 0.0000.\n",
    "\n",
    "However, we can see that sometimes holdout gives a value close to the 2-fold strategy.\n",
    "\n",
    "Truetest and holdout both don't require multiple AUC calculations, so the speed makes sense.\n",
    "\n",
    "#### For the k-fold strategies:\n",
    "\n",
    "It makes sense that time wise the k-fold strategy takes longer than holdout, since it must get an average through many, many AUC calculations. For each split, we see that as there are more splits, the more time the k-fold strategy takes. It seems roughly proportional to the amount of k-folds linearly in these 3 examples.\n",
    "\n",
    "#### For the MCCV:\n",
    "\n",
    "MCCV also needs to get an average through many AUC calculations. As k or s increases, the time also increases, which makes sense, and this therefore can be seen somewhat similar to the k-fold strategies in how it needs to spend more time 'calculating' through each split. MCCV-5 is usually roughly 1/2 the time MCCV-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - Decision Tree Robustness\n",
    "\n",
    "## a.) \n",
    "\n",
    "#### While from my code:\n",
    "```Python\n",
    "def get_param(classifier, xFeat, y, xTest, yTest):\n",
    "    if classifier == \"knn\":\n",
    "        clf = GridSearchCV(\n",
    "            KNeighborsClassifier(),\n",
    "            {'n_neighbors': range(1, 50, 1)},\n",
    "            cv=5, scoring='f1_macro')\n",
    "        clf.fit(xFeat, y['label'])\n",
    "    else:\n",
    "        clf = GridSearchCV(\n",
    "            DecisionTreeClassifier(),\n",
    "            [{'max_depth': range(1, 20),\n",
    "              'min_samples_leaf': range(1, 30),\n",
    "              'criterion': ['entropy', 'gini']}],\n",
    "            cv=5, scoring='f1_macro')\n",
    "        clf.fit(xFeat, y)\n",
    "\n",
    "    optimal_parameter = clf.best_params_\n",
    "    optimal_parameter_string = str(optimal_parameter)\n",
    "\n",
    "    print(\"optimal parameter: \" + optimal_parameter_string)\n",
    "\n",
    "    return optimal_parameter\n",
    "```\n",
    "\n",
    "For Cross Validation for both Decision Tree and KNN, I chose kfold as 5 since 5 was one of the popular choices in the decision tree powerpoint, and also barely the best in my analysis for Q2. It seems here that 10 is also fine from the powerpoint, but I chose not to do that because of my q2 results. \n",
    "\n",
    "See that the 'n_neighbors' range is (1, 50, 1) for KNN, \n",
    "\n",
    "whereas for Decision Tree 'max_depth': range(1, 20), and 'min_samples_leaf': range(1, 30) here\n",
    "\n",
    "As we change these ranges, the best parameters also change. Thus, for these ranges and inputs, the:\n",
    "\n",
    "#### Best Knn Parameter:\n",
    "optimal parameter: {'n_neighbors': 1}\n",
    "\n",
    "#### Best Decision Tree Parameter:\n",
    "optimal parameter: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1}\n",
    "\n",
    "The optimal parameter for knn is n-neighbors 1 because of previous ranges\n",
    "\n",
    "The optimal parameter for the decision tree is entropy, its max_depth 5, and min_samples_leaf is 1 because of previous ranges accordingly\n",
    "\n",
    "\n",
    "## b.) Check out q3.py\n",
    "\n",
    "## c.) Check out q3.py\n",
    "\n",
    "## d.)\n",
    "\n",
    "### Results:\n",
    "#### Overall for KNN:\n",
    "\n",
    "knn auc: 0.72345\n",
    "\n",
    "knn accuracy: 0.85833\n",
    "\n",
    "#### For 5%:\n",
    "\n",
    "knn auc: 0.72224\n",
    "\n",
    "knn accuracy: 0.85625\n",
    "\n",
    "#### For 10%:\n",
    "\n",
    "knn auc: 0.68906\n",
    "\n",
    "knn accuracy: 0.84375\n",
    "\n",
    "#### For 20%:\n",
    "\n",
    "knn auc: 0.70037\n",
    "\n",
    "knn accuracy: 0.85208\n",
    "\n",
    "#### Overall for Decision Tree:\n",
    "\n",
    "decision tree auc: 0.88002\n",
    "\n",
    "decision tree accuracy: 0.88125\n",
    "\n",
    "#### For 5%:\n",
    "\n",
    "decision tree auc: 0.85679\n",
    "\n",
    "decision tree accuracy: 0.86458\n",
    "\n",
    "#### For 10%:\n",
    "\n",
    "decision tree auc: 0.86918\n",
    "\n",
    "decision tree accuracy: 0.9\n",
    "\n",
    "#### For 20%:\n",
    "\n",
    "decision tree auc: 0.86536\n",
    "\n",
    "decision tree accuracy: 0.86667\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Overall, Decision Tree AUC is higher than KNN AUC, whereas their accuracy is closer, but Decision Tree seems to be better in here as well just slightly. Both have similar patterns for accuracy, which seemed to stay generally the same or increase or decrease a little bit as data was lost, but for AUC Decision Tree is the clear winner. \n",
    "\n",
    "Decision Tree for AUC performs higher than KNN when data is lost, but it seems KNN and DT AUC go down as data is lost, which makes sense. \n",
    "\n",
    "KNN for 20% had higher AUC than 10%, which may be an outlier, and DT 10% was higher than DT 5%. Nevertheless, DT AUC is better, staying around a higher range than KNN. Both seem slightly volatile as data is removed, but stay in a consistent range (so far). Since KNN 10% to 20% had a higher gap than DT, if we are to talk technicalities I can conclude KNN has a bit higher sensitivity from these data points. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
