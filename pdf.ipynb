{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Decision Tree\n",
    "\n",
    "## a.) Check out dt.py\n",
    "\n",
    "## b.) Check out dt.py\n",
    "\n",
    "## c.) See Below for 1C\n",
    "\n",
    "## d.) \n",
    "\n",
    "# !!!!!Refactor THIS!!!!\n",
    "Every time there is a split, train must look through all *n* values of all *d* features to find\n",
    "the best split, so we have *nd*. There is at least one split at each level, so total time to\n",
    "train is O(*ndp*), where *p* is the maximum depth. Predict would be like searching in a red black tree, since it has to get to a leaf node. This takes O(*p*) time as the furthest possible leaf would be at the max depth, and predict would have take make a comparison for every node from and including the root till that leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - c.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Model Assessment\n",
    "\n",
    "## a.) Check out q2.py\n",
    "\n",
    "## b.) Check out q2.py\n",
    "\n",
    "## c.) Check out q2.py\n",
    "\n",
    "## d.) \n",
    "\n",
    "### Result:\n",
    "![Q3 Results](q3.png)\n",
    "```Python\n",
    "6   True Test  0.954458  0.828526  0.000000\n",
    "```\n",
    "\n",
    "### Analysis\n",
    "\n",
    "We can see that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - Decision Tree Robustness\n",
    "\n",
    "## a.) \n",
    "\n",
    "#### For: \n",
    "\n",
    "python3 q3.py 5 10\n",
    "\n",
    "#### While from my code:\n",
    "```Python\n",
    "def get_param(classifier, xFeat, y, xTest, yTest):\n",
    "    if classifier == \"knn\":\n",
    "        clf = GridSearchCV(\n",
    "            KNeighborsClassifier(),\n",
    "            {'n_neighbors': range(1, 50, 1)},\n",
    "            cv=5, scoring='f1_macro')\n",
    "        clf.fit(xFeat, y['label'])\n",
    "    else:\n",
    "        clf = GridSearchCV(\n",
    "            DecisionTreeClassifier(),\n",
    "            [{'max_depth': range(1, 20),\n",
    "              'min_samples_leaf': range(1, 30),\n",
    "              'criterion': ['entropy', 'gini']}],\n",
    "            cv=5, scoring='f1_macro')\n",
    "        clf.fit(xFeat, y)\n",
    "\n",
    "    optimal_parameter = clf.best_params_\n",
    "    optimal_parameter_string = str(optimal_parameter)\n",
    "\n",
    "    print(\"optimal parameter: \" + optimal_parameter_string)\n",
    "\n",
    "    return optimal_parameter\n",
    "```\n",
    "\n",
    "See that the 'n_neighbors' range is (1, 50, 1) for KNN, \n",
    "\n",
    "whereas for Decision Tree 'max_depth': range(1, 20), and 'min_samples_leaf': range(1, 30) here\n",
    "\n",
    "#### Best Knn Parameter:\n",
    "optimal parameter: {'n_neighbors': 1}\n",
    "\n",
    "#### Best Decision Tree Parameter:\n",
    "optimal parameter: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1}\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Therefore,\n",
    "\n",
    "## b.) Check out q3.py\n",
    "\n",
    "## c.) Check out q3.py\n",
    "\n",
    "## d.)\n",
    "\n",
    "### Results:\n",
    "#### Overall for KNN:\n",
    "\n",
    "knn auc: 0.72345\n",
    "\n",
    "knn percent accuracy: 0.85833\n",
    "\n",
    "#### For 5%:\n",
    "\n",
    "knn auc: 0.72224\n",
    "\n",
    "knn percent accuracy: 0.85625\n",
    "\n",
    "#### For 10%:\n",
    "\n",
    "knn auc: 0.68906\n",
    "\n",
    "knn percent accuracy: 0.84375\n",
    "\n",
    "#### For 20%:\n",
    "\n",
    "knn auc: 0.70037\n",
    "\n",
    "knn percent accuracy: 0.85208\n",
    "\n",
    "#### Overall for Decision Tree:\n",
    "\n",
    "decision tree auc: 0.88002\n",
    "\n",
    "decision tree percent accuracy: 0.88125\n",
    "\n",
    "#### For 5%:\n",
    "\n",
    "decision tree auc: 0.85679\n",
    "\n",
    "decision tree percent accuracy: 0.86458\n",
    "\n",
    "#### For 10%:\n",
    "\n",
    "decision tree auc: 0.86918\n",
    "\n",
    "decision tree percent accuracy: 0.9\n",
    "\n",
    "#### For 20%:\n",
    "\n",
    "decision tree auc: 0.86536\n",
    "\n",
    "decision tree percent accuracy: 0.86667\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Therefore,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
