{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Decision Tree\n",
    "\n",
    "## a.) Check out dt.py\n",
    "\n",
    "## b.) Check out dt.py\n",
    "\n",
    "## c.) See Below for 1C\n",
    "\n",
    "## d.) \n",
    "\n",
    "For every split, since the train method goes through every *d* feature, through all their *n* values to get the optimal split, for this mandatory method so far we have at least *dn*\n",
    "\n",
    "For each level, we have one split, so since we train at each level to the maximum depth, so let us make the depth of the entire tree *p*. Thus, we get O(*dnp*). This is for train.\n",
    "\n",
    "For predict, it is O(*np*) because this is like searching in a binary tree getting to the leaf node, which results in the max depth, where predict, from the root to the leaf it results in makes a comparison to reach that node (which costs *n*).   \n",
    " and predict would have take make a comparison for every node from and including the root till that leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - c.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import q1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Check out q2.py\n",
    "\n",
    "## b.) Check out q2.py\n",
    "\n",
    "## c.) Check out q2.py\n",
    "\n",
    "## d.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are three runs of the model assessment, which is the amount of runs my laptop would fit on the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model Assessment](q3.PNG)\n",
    "```Python\n",
    "6   True Test  0.954458  0.828526  0.000000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "AUC Comparison:\n",
    "\n",
    "We can see that TrainAUC is higher than ValAUC at every single row and column position, and this remains consistently so. We can assume that there is at least a general .1 advantage to TrainAUC vs. ValAUC for any strategy.\n",
    "\n",
    "Different Model Selection Techniques vs. AUC:\n",
    "\n",
    "TrainAUC and ValAUC seems generally similar for each technique, but through a thorough analysis of variances, we can see that:\n",
    "\n",
    "2-fold TrainAUC has a 0 variance. 2-fold, 5-fold, and 10-fold have notably low variances for\n",
    "ValAUC when compared to the other methods, with Holdout and MCCV w/10 having the highest variance for ValAUC. From this along with 5-fold consistently having ValAUC very close to 0.8, I think 5-fold is the most robust. \n",
    "\n",
    "Computation Time:\n",
    "Holdout & True-test:\n",
    "True Test is always the fastest, with holdout sometimes coming in 2nd.\n",
    "\n",
    "My laptop is just so speedy that sometimes holdout gives 0.0000.\n",
    "\n",
    "However, we can see that sometimes holdout gives a value close to the 2-fold strategy.\n",
    "\n",
    "Truetest and holdout both don't require multiple AUC calculations, so the speed makes sense.\n",
    "\n",
    "For the k-fold strategies:\n",
    "It makes sense that time wise the k-fold strategy takes longer than holdout, since it must get an average through many, many AUC calculations. For each split, we see that as there are more splits, the more time the k-fold strategy takes. It seems roughly proportional to the amount of k-folds linearly in these 3 examples. \n",
    "\n",
    "After running my code 50 times:\n",
    "\n",
    "\n",
    "We can see that:\n",
    "\n",
    "\n",
    "For the MCCV:\n",
    "MCCV also needs to get an average through many AUC calculations. As k or s increases, the time also increases, which makes sense, and this therefore can be seen somewhat similar to the k-fold strategies in how it needs to spend more time 'calculating' through each split. MCCV-5 is usually roughly 1/2 the time MCCV-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - Decision Tree Robustness\n",
    "\n",
    "## a.) \n",
    "\n",
    "#### For: \n",
    "\n",
    "python3 q3.py 5 10\n",
    "\n",
    "#### While from my code:\n",
    "```Python\n",
    "def get_param(classifier, xFeat, y, xTest, yTest):\n",
    "    if classifier == \"knn\":\n",
    "        clf = GridSearchCV(\n",
    "            KNeighborsClassifier(),\n",
    "            {'n_neighbors': range(1, 50, 1)},\n",
    "            cv=5, scoring='f1_macro')\n",
    "        clf.fit(xFeat, y['label'])\n",
    "    else:\n",
    "        clf = GridSearchCV(\n",
    "            DecisionTreeClassifier(),\n",
    "            [{'max_depth': range(1, 20),\n",
    "              'min_samples_leaf': range(1, 30),\n",
    "              'criterion': ['entropy', 'gini']}],\n",
    "            cv=5, scoring='f1_macro')\n",
    "        clf.fit(xFeat, y)\n",
    "\n",
    "    optimal_parameter = clf.best_params_\n",
    "    optimal_parameter_string = str(optimal_parameter)\n",
    "\n",
    "    print(\"optimal parameter: \" + optimal_parameter_string)\n",
    "\n",
    "    return optimal_parameter\n",
    "```\n",
    "\n",
    "See that the 'n_neighbors' range is (1, 50, 1) for KNN, \n",
    "\n",
    "whereas for Decision Tree 'max_depth': range(1, 20), and 'min_samples_leaf': range(1, 30) here\n",
    "\n",
    "#### Best Knn Parameter:\n",
    "optimal parameter: {'n_neighbors': 1}\n",
    "\n",
    "#### Best Decision Tree Parameter:\n",
    "optimal parameter: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1}\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Therefore,\n",
    "\n",
    "## b.) Check out q3.py\n",
    "\n",
    "## c.) Check out q3.py\n",
    "\n",
    "## d.)\n",
    "\n",
    "### Results:\n",
    "#### Overall for KNN:\n",
    "\n",
    "knn auc: 0.72345\n",
    "\n",
    "knn percent accuracy: 0.85833\n",
    "\n",
    "#### For 5%:\n",
    "\n",
    "knn auc: 0.72224\n",
    "\n",
    "knn percent accuracy: 0.85625\n",
    "\n",
    "#### For 10%:\n",
    "\n",
    "knn auc: 0.68906\n",
    "\n",
    "knn percent accuracy: 0.84375\n",
    "\n",
    "#### For 20%:\n",
    "\n",
    "knn auc: 0.70037\n",
    "\n",
    "knn percent accuracy: 0.85208\n",
    "\n",
    "#### Overall for Decision Tree:\n",
    "\n",
    "decision tree auc: 0.88002\n",
    "\n",
    "decision tree percent accuracy: 0.88125\n",
    "\n",
    "#### For 5%:\n",
    "\n",
    "decision tree auc: 0.85679\n",
    "\n",
    "decision tree percent accuracy: 0.86458\n",
    "\n",
    "#### For 10%:\n",
    "\n",
    "decision tree auc: 0.86918\n",
    "\n",
    "decision tree percent accuracy: 0.9\n",
    "\n",
    "#### For 20%:\n",
    "\n",
    "decision tree auc: 0.86536\n",
    "\n",
    "decision tree percent accuracy: 0.86667\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Therefore,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
